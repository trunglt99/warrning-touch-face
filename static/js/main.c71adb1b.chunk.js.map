{"version":3,"sources":["assets/hey_sondn.mp3","App.js","reportWebVitals.js","index.js"],"names":["sound","Howl","src","soundURL","TOUCHED_LABEL","App","video","useRef","classifier","canPlaySond","mobilenetModule","useState","touch","setTouched","init","a","console","log","setupCamera","current","kmmClassifier","mobilenet","initNotifications","colldown","Promise","resolve","reject","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","stream","srcObject","addEventListener","error","train","label","i","parseInt","training","embedding","infer","addExample","sleep","run","predictClass","result","confidences","play","notify","body","ms","setTimeout","useEffect","on","className","ref","autoPlay","onClick","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"yYAAe,MAA0B,sC,SCSrCA,EAAQ,IAAIC,OAAK,CACnBC,IAAK,CAACC,KAGFC,EAAgB,UAkHPC,MA/Gf,WACE,IAAMC,EAAQC,mBACRC,EAAaD,mBACbE,EAAcF,kBAAO,GACrBG,EAAkBH,mBAJX,EAKeI,oBAAS,GALxB,mBAKNC,EALM,KAKCC,EALD,KAMPC,EAAI,uCAAG,sBAAAC,EAAA,6DACXC,QAAQC,IAAI,WADD,SAELC,IAFK,cAGXF,QAAQC,IAAI,wBACZT,EAAWW,QAAUC,MAJV,SAKqBC,MALrB,OAKXX,EAAgBS,QALL,OAMXH,QAAQC,IAAI,cACZD,QAAQC,IAAI,gCACZK,YAAkB,CAACC,SAAU,MARlB,4CAAH,qDAWJL,EAAc,WAClB,OAAO,IAAIM,SAAQ,SAACC,EAASC,GAC3BC,UAAUC,aAAeD,UAAUC,cACnCD,UAAUE,oBACVF,UAAUG,iBACVH,UAAUI,eAEPJ,UAAUC,aACXD,UAAUC,aACR,CAACtB,OAAO,IACR,SAAA0B,GACE1B,EAAMa,QAAQc,UAAYD,EAC1B1B,EAAMa,QAAQe,iBAAiB,aAAaT,MAE9C,SAAAU,GAAK,OAAIT,EAAOS,MAGlBT,QAIAU,EAAK,uCAAG,WAAMC,GAAN,eAAAtB,EAAA,sDACZC,QAAQC,IAAR,WAAgBoB,EAAhB,iBACSC,EAAE,EAFC,YAEEA,EA1CK,IAwCP,uBAGXtB,QAAQC,IAAR,mBAAwBsB,SAASD,EAAE,GA3CjB,GA2CuC,IAAzD,MAHW,SAINE,EAASH,GAJH,SAEsBC,EAFtB,0DAAH,sDAQLE,EAAW,SAAAH,GACf,OAAO,IAAIb,QAAJ,uCAAY,WAAOC,GAAP,eAAAV,EAAA,6DACX0B,EAAY/B,EAAgBS,QAAQuB,MAC3CpC,EAAMa,SACN,GAECX,EAAWW,QAAQwB,WAAWF,EAAWJ,GALxB,SAMXO,EAAM,KANK,OAOjBnB,IAPiB,2CAAZ,wDAUHoB,EAAG,uCAAG,8BAAA9B,EAAA,6DACJ0B,EAAY/B,EAAgBS,QAAQuB,MACxCpC,EAAMa,SACN,GAHQ,SAKWX,EAAWW,QAAQ2B,aAAaL,GAL3C,cAKJM,EALI,QAOFV,QAAUjC,GACjB2C,EAAOC,YAAYD,EAAOV,OAlEJ,IAoEtBrB,QAAQC,IAAI,WACZR,EAAYU,SAAU,EACtBnB,EAAMiD,OACNC,YAAO,aAAc,CAAEC,KAAK,6BAC5BtC,GAAW,KAGXG,QAAQC,IAAI,eACZJ,GAAW,IAlBF,SAoBJ+B,EAAM,KApBF,OAqBVC,IArBU,2CAAH,qDAuBHD,EAAQ,WAAa,IAAZQ,EAAW,uDAAN,EAClB,OAAO,IAAI5B,SAAQ,SAAAC,GAAO,OAAI4B,WAAW5B,EAAS2B,OAYpD,OAVAE,qBAAU,WAMN,OAJAxC,IACAd,EAAMuD,GAAG,OAAO,WACd9C,EAAYU,SAAU,KAEjB,eAGT,IAEA,sBAAKqC,UAAS,eAAU5C,EAAQ,UAAY,KAA5C,UACD,+CACA,uBACA6C,IAAKnD,EACLkD,UAAU,QACVE,UAAQ,IAER,sBAAKF,UAAU,UAAf,UACH,wBAAQA,UAAU,MAAMG,QAAS,kBAAKvB,EA1Gf,cA0GvB,qBACA,wBAAQoB,UAAU,MAAMG,QAAS,kBAAKvB,EAAMhC,IAA5C,qBACA,wBAAQoD,UAAU,MAAMG,QAAS,kBAAKd,KAAtC,wBC5Gee,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.c71adb1b.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/hey_sondn.8c2f8e9b.mp3\";","import React, {useEffect, useRef,useState} from 'react';\nimport './App.css';\nimport * as mobilenet from '@tensorflow-models/mobilenet';\nimport * as kmmClassifier from '@tensorflow-models/knn-classifier';\nimport * as tf from '@tensorflow/tfjs';\nimport {Howl} from 'howler';\nimport soundURL from './assets/hey_sondn.mp3';\nimport { initNotifications, notify} from '@mycv/f8-notification';\n\nvar sound = new Howl({\n  src: [soundURL]\n});\nconst NOT_TOUCH_LABEL= 'not_Touch';\nconst TOUCHED_LABEL = 'touched';\nconst TRAINING_TIMES = 50;\nconst TOUCHED_CONFIDENCE = 0.8;\nfunction App() {\n  const video = useRef();\n  const classifier = useRef();\n  const canPlaySond = useRef(true);\n  const mobilenetModule = useRef(); \n  const [touch, setTouched] = useState(false);\n  const init = async() =>{\n    console.log('init...');\n    await setupCamera();\n    console.log('setup camera success');\n    classifier.current = kmmClassifier.create();\n    mobilenetModule.current = await mobilenet.load();\n    console.log('setup done');\n    console.log('no touch face button train 1');\n    initNotifications({colldown: 3000 });\n  }\n\n  const setupCamera = () => {\n    return new Promise((resolve, reject) => {\n      navigator.getUserMedia = navigator.getUserMedia || \n      navigator.webkitGetUserMedia || \n      navigator.mozGetUserMedia || \n      navigator.msGetUserMedia;\n\n      if(navigator.getUserMedia) {\n        navigator.getUserMedia(\n          {video: true},\n          stream => {\n            video.current.srcObject = stream;\n            video.current.addEventListener('loadeddata',resolve)\n          },\n          error => reject(error)\n        );\n           } else {\n        reject();\n      } \n    });\n  }\n  const train = async label => {\n    console.log(`[${label}] Dang train`);\n    for (let i=0; i<TRAINING_TIMES; ++i) {\n     console.log(`progress ${parseInt(i+1) / TRAINING_TIMES * 100}%`);\n    await training(label);\n    }\n  }\n\n  const training = label => {\n    return new Promise(async  resolve => {\n      const embedding = mobilenetModule.current.infer(\n     video.current,\n     true\n      );\n      classifier.current.addExample(embedding, label);\n      await sleep(100);\n      resolve();\n    });\n  }\n  const run = async() => {\n    const embedding = mobilenetModule.current.infer(\n      video.current,\n      true\n    );\n    const result = await classifier.current.predictClass(embedding);\n   if (\n     result.label === TOUCHED_LABEL &&\n     result.confidences[result.label] > TOUCHED_CONFIDENCE\n   ) {\n     console.log('Touched');\n     canPlaySond.current = false;\n     sound.play();\n     notify('Bo tay ra!', { body:'Ban vau cham tay vao mat'})\n     setTouched(true);\n   }else\n   {\n     console.log('not touched');\n     setTouched(false);\n   }\n    await sleep(200);\n    run();\n  }\n  const sleep = (ms = 0) => {\n    return new Promise(resolve => setTimeout(resolve, ms))\n  }\n  useEffect(() => {\n    \n      init();\n      sound.on('end', function(){\n        canPlaySond.current = true;\n      })\n      return () => {\n    }\n\n  },[]);\n  return (\n    <div className={`main ${touch ? 'touched' : ' '}`}>\n   <h1>HELLO REACTJS</h1>\n   <video\n   ref={video}\n   className=\"video\"\n   autoPlay\n   />\n   <div className=\"control\">\n<button className=\"btn\" onClick={()=> train(NOT_TOUCH_LABEL)}>Train 1</button>\n<button className=\"btn\" onClick={()=> train(TOUCHED_LABEL)}>Train 2</button>\n<button className=\"btn\" onClick={()=> run()}>Run</button>\n   </div>\n\n    </div>  \n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}